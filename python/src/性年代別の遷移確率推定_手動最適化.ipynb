{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T08:36:20.897321200Z",
     "start_time": "2024-09-21T08:36:20.834307300Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import cvxpy as cp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "\"\"\"pathの定義\"\"\"\n",
    "DIR_HOURLY = 'Z:/lab/lifebehavior/2020_jikoku_danjonenso.csv'\n",
    "DIR_FULL_DAY = 'Z:/lab/lifebehavior/2020_4shihyo_danjonenso.csv'\n",
    "DIR_GENRE = 'Z:/lab/lifebehavior/nhk_genre.csv'\n",
    "\n",
    "\n",
    "\n",
    "def calc_list_diff(list1:list, list2:list):\n",
    "    # リストの長さが異なる場合のエラーチェック\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"リストの長さが異なります。\")\n",
    "    \n",
    "    # 各要素の差分を計算して新しいリストを生成\n",
    "    difference = [a - b for a, b in zip(list1, list2)]\n",
    "    return difference\n",
    "\n",
    "# not P_iの算出による P_iの算出\n",
    "def get_P_i(hourly_table:pd.DataFrame,Transition_rates:list,activity_ordering:list):\n",
    "    t_0_table = sort_df_by_list(hourly_table[(hourly_table[\"Time\"].dt.hour == 0) & (hourly_table[\"Time\"].dt.minute == 0)],\"Activity\",activity_ordering).copy()\n",
    "    initial_rate = np.array(t_0_table[\"Rate\"])\n",
    "\n",
    "    # 正規化\n",
    "    initial_rate = initial_rate / np.sum(initial_rate)\n",
    "\n",
    "    P_i_list = []\n",
    "    for i in range(len(activity_ordering)):\n",
    "\n",
    "        # 行列の加工\n",
    "        n = len(initial_rate)\n",
    "        one_vector = np.ones(n)\n",
    "        modified_transition_rates = []\n",
    "\n",
    "        for A in Transition_rates:\n",
    "            A_i = A.copy()\n",
    "            A_i[i, :] = 0  # 行 i を全て 0 に置き換える\n",
    "            modified_transition_rates.append(A_i)\n",
    "\n",
    "        # 初期行為者率ベクトルの加工\n",
    "        modified_initial_rate = initial_rate.copy()\n",
    "        modified_initial_rate[i] = 0\n",
    "\n",
    "        # 最終的な行為者率ベクトルの計算\n",
    "        final_rate = modified_initial_rate\n",
    "\n",
    "        for A_i in modified_transition_rates:\n",
    "            final_rate = A_i @ final_rate\n",
    "\n",
    "        # 行為 i を一度も行わない確率の計算\n",
    "        P_not_i = one_vector @ final_rate\n",
    "\n",
    "        P_i = 1-P_not_i\n",
    "\n",
    "        # 独自定義のラベルを適用しているため、重複集計の関係上どうしても例外が発生する。\n",
    "        if P_i < 0:\n",
    "            P_i = 0\n",
    "\n",
    "        P_i_list.append(P_i)\n",
    "\n",
    "    return P_i_list\n",
    "\n",
    "# データフレームを参照リストに基づいてソートするヘルパー関数\n",
    "def sort_df_by_list(df, column, reference_list):\n",
    "    return df.set_index(column).reindex(reference_list).reset_index()\n",
    "\n",
    "# 遷移率を計算する関数\n",
    "def calc_transition_rates(beta_i: np.ndarray, time_list: list, time_table: pd.DataFrame, activity_list: list):\n",
    "    transition_rates = []\n",
    "    middle = activity_list  # 活動のリストを基準として使用\n",
    "    \n",
    "    for i in range(len(time_list)):\n",
    "        time_t = time_list[i]\n",
    "        time_t1 = time_list[(i+1) % len(time_list)]  # 次の時間帯\n",
    "        \n",
    "        # 両方の時間帯の行動率を取得\n",
    "        # y_t = np.array(sort_df_by_list(time_table[(time_table[\"Time\"].dt.hour == time_t.hour) & (time_table[\"Time\"].dt.minute == time_t.minute) ], \"Activity\", middle)[\"Rate\"])\n",
    "        # y_t1 = np.array(sort_df_by_list(time_table[(time_table[\"Time\"].dt.hour == time_t1.hour) & (time_table[\"Time\"].dt.minute == time_t1.minute) ], \"Activity\", middle)[\"Rate\"])\n",
    "\n",
    "        y_t = np.array(sort_df_by_list(time_table[(time_table[\"Time\"].dt.hour == pd.Timestamp(time_t).hour) & (time_table[\"Time\"].dt.minute == pd.Timestamp(time_t).minute)], \"Activity\", middle)[\"Rate\"])\n",
    "        y_t1 = np.array(sort_df_by_list(time_table[(time_table[\"Time\"].dt.hour == pd.Timestamp(time_t1).hour) & (time_table[\"Time\"].dt.minute == pd.Timestamp(time_t1).minute)], \"Activity\", middle)[\"Rate\"])\n",
    "        \n",
    "        # 変数の定義\n",
    "        no_of_elem = len(middle)\n",
    "        a = cp.Variable((no_of_elem, no_of_elem), nonneg=True)  # 非負の要素を持つ遷移行列\n",
    "\n",
    "        # 目的関数と制約条件の定義\n",
    "        delta = np.eye(no_of_elem)  # クロネッカーのデルタ\n",
    "        # 目的関数: (1 - beta_i * delta) で修正された、二乗差の合計を最小化\n",
    "        objective = cp.Minimize(cp.sum(cp.multiply(1 - beta_i * delta, cp.square(a))))\n",
    "\n",
    "        # 行の和が1になる制約に変更\n",
    "        constraints = [\n",
    "            cp.sum(a, axis=1) == 1,  # 遷移行列の各行の和が1になる制約\n",
    "            a >= 0,  # 非負制約\n",
    "        ]\n",
    "\n",
    "        # 行動率を正規化\n",
    "        y_t = y_t / np.sum(y_t)\n",
    "        y_t1 = y_t1 / np.sum(y_t1)\n",
    "\n",
    "        # 次の時間帯の行動率と遷移行列の適用が一致する制約\n",
    "        constraints.append(y_t1 - a.T @ y_t == 0)\n",
    "\n",
    "        # 問題を定義する\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "\n",
    "        # ソルバーを使用して問題を解く（別のソルバーを指定して解く）\n",
    "        problem.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "        # 得られた遷移行列を格納\n",
    "        transition_rates.append(a.value)\n",
    "\n",
    "    return np.array(transition_rates)\n",
    "\n",
    "def roulette_wheel_selection(weights:list,labels:list):\n",
    "    \"\"\"\n",
    "    Performs roulette wheel selection on a list of weights.\n",
    "    \n",
    "    Args:\n",
    "    weights (list of float): The weights or probabilities for each item.\n",
    "    \n",
    "    Returns:\n",
    "    int: The index of the selected item.\n",
    "    \"\"\"\n",
    "    if (len(weights) != len(labels)):\n",
    "        print(\"weights and labels has different length @roulette_wheel_selection\")\n",
    "        os._exit(1)\n",
    "    # Calculate the cumulative sum of weights\n",
    "    cumulative_sum = [sum(weights[:i+1]) for i in range(len(weights))]\n",
    "    total_sum = cumulative_sum[-1]\n",
    "    \n",
    "    # Generate a random number in the range [0, total_sum)\n",
    "    random_num = random.uniform(0, total_sum)\n",
    "    \n",
    "    # Find the index where the random number would fit in the cumulative sum\n",
    "    for i, cum_sum in enumerate(cumulative_sum):\n",
    "        if random_num < cum_sum:\n",
    "            return i, labels[i]\n",
    "        \n",
    "# 目的関数\n",
    "def objective(beta_i:np.ndarray, time_list:list, time_table:pd.DataFrame, activity_list:list,orig_P_i:list):\n",
    "    transition_rates = calc_transition_rates(beta_i, time_list, time_table, activity_list)\n",
    "    calclated_P_i = get_P_i(time_table,transition_rates,activity_list) # 一日のユニークな行為者率の算出\n",
    "    diff_1 = [e for e in calc_list_diff(orig_P_i,calclated_P_i)]\n",
    "    diff_2 = sum([e**2 for e in diff_1])\n",
    "    return diff_2,diff_1\n",
    "\n",
    "# 各粒子の評価を並列で行う関数\n",
    "def evaluate_particle(objective, particle_position, time_list, time_table, activity_ordering, orig_P_i):\n",
    "    return objective(particle_position, time_list, time_table, activity_ordering, orig_P_i)[0]\n",
    "\n",
    "# βのパラメータフィッティング\n",
    "def pso(objective, bounds, n_iterations, num_particles, w, c1, c2, time_list, time_table, activity_ordering, orig_P_i):\n",
    "    # 粒子の位置と速度を初期化\n",
    "    num_dimensions = len(activity_ordering)\n",
    "    particles_position = np.random.uniform(bounds[:, 0], bounds[:, 1], (num_particles, num_dimensions))\n",
    "    particles_velocity = np.random.uniform(-1, 1, (num_particles, num_dimensions))\n",
    "\n",
    "    # 粒子の最良位置と全体の最良位置を初期化\n",
    "    personal_best_position = particles_position.copy()\n",
    "    \n",
    "    # 並列で初期評価を計算\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        personal_best_eval = list(executor.map(lambda p: evaluate_particle(objective, p, time_list, time_table, activity_ordering, orig_P_i), particles_position))\n",
    "    \n",
    "    global_best_position = personal_best_position[np.argmin(personal_best_eval)]\n",
    "    global_best_eval = np.min(personal_best_eval)\n",
    "\n",
    "    print(f\"Starting PSO >>> Initial Global Best Evaluation : {global_best_eval}\")\n",
    "\n",
    "    for i in tqdm(range(n_iterations)):\n",
    "        for j in range(num_particles):\n",
    "            # 粒子の速度を更新\n",
    "            r1 = np.random.rand(num_dimensions)\n",
    "            r2 = np.random.rand(num_dimensions)\n",
    "            particles_velocity[j] = (w * particles_velocity[j] +\n",
    "                                     c1 * r1 * (personal_best_position[j] - particles_position[j]) +\n",
    "                                     c2 * r2 * (global_best_position - particles_position[j]))\n",
    "            \n",
    "            # 粒子の位置を更新\n",
    "            particles_position[j] += particles_velocity[j]\n",
    "            particles_position[j] = np.clip(particles_position[j], bounds[:, 0], bounds[:, 1])  # 境界のチェック\n",
    "        \n",
    "        # 並列で各粒子の評価を計算\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            current_evals = list(executor.map(lambda p: evaluate_particle(objective, p, time_list, time_table, activity_ordering, orig_P_i), particles_position))\n",
    "        \n",
    "        # 粒子の最良位置を更新\n",
    "        for j in range(num_particles):\n",
    "            if current_evals[j] < personal_best_eval[j]:\n",
    "                personal_best_position[j] = particles_position[j].copy()\n",
    "                personal_best_eval[j] = current_evals[j]\n",
    "            \n",
    "            # 全体の最良位置を更新\n",
    "            if current_evals[j] < global_best_eval:\n",
    "                global_best_position = particles_position[j].copy()\n",
    "                global_best_eval = current_evals[j]\n",
    "                print(f\"Global Best Evaluation is Updated [Iteration {i+1}] : {global_best_eval}\")\n",
    "\n",
    "    return global_best_position, global_best_eval\n",
    "\n",
    "\n",
    "# パラメータを動的に調整する関数\n",
    "def update_parameters(iteration, n_iterations, w_min, c1_min, c2_min, w_max, c1_max, c2_max):\n",
    "    # イテレーションに基づいて慣性項wを線形に減少させる\n",
    "    w = w_max - ((w_max - w_min) * iteration / n_iterations)\n",
    "    \n",
    "    # イテレーションに基づいてc1, c2を動的に調整する\n",
    "    c1 = c1_max - ((c1_max - c1_min) * iteration / n_iterations)\n",
    "    c2 = c2_min + ((c2_max - c2_min) * iteration / n_iterations)\n",
    "    \n",
    "    return w, c1, c2\n",
    "\n",
    "# 動的なpsoパラメータによるβのパラメータフィッティング\n",
    "def pso_dynamic(objective, bounds, n_iterations, num_particles, w_min, c1_min, c2_min, w_max, c1_max, c2_max, time_list, time_table, activity_ordering, orig_P_i):\n",
    "    # 粒子の位置と速度を初期化\n",
    "    num_dimensions = len(activity_ordering)\n",
    "    particles_position = np.random.uniform(bounds[:, 0], bounds[:, 1], (num_particles, num_dimensions))\n",
    "    particles_velocity = np.random.uniform(-1, 1, (num_particles, num_dimensions))\n",
    "\n",
    "    # 粒子の最良位置と全体の最良位置を初期化\n",
    "    personal_best_position = particles_position.copy()\n",
    "    \n",
    "    # 並列で初期評価を計算\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        personal_best_eval = list(executor.map(lambda p: evaluate_particle(objective, p, time_list, time_table, activity_ordering, orig_P_i), particles_position))\n",
    "    \n",
    "    global_best_position = personal_best_position[np.argmin(personal_best_eval)]\n",
    "    global_best_eval = np.min(personal_best_eval)\n",
    "\n",
    "    print(f\"Starting PSO >>> Initial Global Best Evaluation : {global_best_eval}\")\n",
    "\n",
    "    for i in tqdm(range(n_iterations)):\n",
    "        w, c1, c2 = update_parameters(i, n_iterations, w_min, c1_min, c2_min, w_max, c1_max, c2_max)\n",
    "        \n",
    "        for j in range(num_particles):\n",
    "            # 粒子の速度を更新\n",
    "            r1 = np.random.rand(num_dimensions)\n",
    "            r2 = np.random.rand(num_dimensions)\n",
    "            particles_velocity[j] = (w * particles_velocity[j] +\n",
    "                                     c1 * r1 * (personal_best_position[j] - particles_position[j]) +\n",
    "                                     c2 * r2 * (global_best_position - particles_position[j]))\n",
    "            \n",
    "            # 粒子の位置を更新\n",
    "            particles_position[j] += particles_velocity[j]\n",
    "            particles_position[j] = np.clip(particles_position[j], bounds[:, 0], bounds[:, 1])  # 境界のチェック\n",
    "        \n",
    "        # 並列で各粒子の評価を計算\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            current_evals = list(executor.map(lambda p: evaluate_particle(objective, p, time_list, time_table, activity_ordering, orig_P_i), particles_position))\n",
    "        \n",
    "        # 粒子の最良位置を更新\n",
    "        for j in range(num_particles):\n",
    "            if current_evals[j] < personal_best_eval[j]:\n",
    "                personal_best_position[j] = particles_position[j].copy()\n",
    "                personal_best_eval[j] = current_evals[j]\n",
    "            \n",
    "            # 全体の最良位置を更新\n",
    "            if current_evals[j] < global_best_eval:\n",
    "                global_best_position = particles_position[j].copy()\n",
    "                global_best_eval = current_evals[j]\n",
    "                print(f\"Global Best Evaluation is Updated [Iteration {i+1}] : {global_best_eval}\")\n",
    "\n",
    "    return global_best_position, global_best_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T08:36:22.929879800Z",
     "start_time": "2024-09-21T08:36:22.751888900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 214.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# 最良評価値が高い順にソート（評価値が高い、最適化が不十分な属性から優先する仕様）\n",
    "# 初期化\n",
    "group_dict = {}\n",
    "\n",
    "# 各属性ごとに処理\n",
    "for label in tqdm([\n",
    "        '男１０代', '男２０代', '男３０代', '男４０代', '男５０代', '男６０代', '男７０歳以上',\n",
    "        '女１０代', '女２０代', '女３０代', '女４０代', '女５０代', '女６０代', '女７０歳以上']):\n",
    "    \n",
    "    for day in [\"平日\", \"土曜日\", \"日曜日\"]:\n",
    "        smallest_group = None\n",
    "        smallest_eval = float('inf')  # 初期値を無限大に設定\n",
    "        \n",
    "        # 各パスの評価値を比較\n",
    "        for path in glob.glob(f\"Z:/lab/lifebehavior/βパラメータ_{label}_{day}-*-.pickle\"):\n",
    "            try:\n",
    "                evaluation = float(path.split(\"-\")[1])  # 評価値の抽出\n",
    "                if evaluation < smallest_eval:\n",
    "                    smallest_eval = evaluation\n",
    "                    smallest_group = (label,day)\n",
    "            except ValueError:\n",
    "                continue  # 評価値が数値でない場合はスキップ\n",
    "        \n",
    "        if smallest_group != None:\n",
    "            group_dict[smallest_group] = smallest_eval\n",
    "\n",
    "# 評価値が大きい順にソートされたパスのリストを作成\n",
    "sorted_groups = sorted(group_dict.keys(), key=lambda x: group_dict[x], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T08:50:00.359507900Z",
     "start_time": "2024-09-21T08:49:51.079070900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Group label:男７０歳以上 day:土曜日\n",
      "eval2: 1.9494778476130739\n",
      "睡眠 -0.004639722374994992\n",
      "食事 0.059702168947858625\n",
      "身のまわりの用事 0.19186356187634612\n",
      "療養・静養 0.077\n",
      "仕事 0.258\n",
      "仕事のつきあい 0.028999999999999998\n",
      "授業・学内の活動 0.005\n",
      "学校外の学習 0.0\n",
      "炊事・掃除・洗濯 0.392\n",
      "買い物 0.325\n",
      "子どもの世話 0.033\n",
      "家庭雑事 0.306\n",
      "通勤 0.12\n",
      "通学 0.005\n",
      "社会参加 0.12\n",
      "会話・交際 0.16699999999999998\n",
      "スポーツ 0.182\n",
      "行楽・散策 0.191\n",
      "趣味・娯楽・教養 0.048\n",
      "マスメディア接触 1.1420131286799402\n",
      "休息 0.22111164410553774\n"
     ]
    }
   ],
   "source": [
    "# 手動用に目的関数を調整\n",
    "def objective_manual(beta_i:np.ndarray, time_list:list, time_table:pd.DataFrame, activity_list:list,orig_P_i:list):\n",
    "    transition_rates = calc_transition_rates(beta_i, time_list, time_table, activity_list)\n",
    "    calclated_P_i = get_P_i(time_table,transition_rates,activity_list) # 一日のユニークな行為者率の算出\n",
    "    diff_1 = [e for e in calc_list_diff(orig_P_i,calclated_P_i)]\n",
    "    diff_2 = sum([e**2 for e in diff_1])\n",
    "    return diff_2,diff_1\n",
    "# 独自定義のラベルを適用するためにまず辞書を作る\n",
    "small = [\n",
    "    \"睡眠\", \"食事\", \"身のまわりの用事\", \"療養・静養\", \"仕事\", \"仕事のつきあい\", \n",
    "    \"授業・学内の活動\", \"学校外の学習\", \"炊事・掃除・洗濯\", \"買い物\", \n",
    "    \"子どもの世話\", \"家庭雑事\", \"通勤\", \"通学\", \"社会参加\", \"会話・交際\", \n",
    "    \"スポーツ\", \"行楽・散策\", \"趣味・娯楽・教養(インターネット除く)\", \n",
    "    \"趣味・娯楽・教養のインターネット(動画除く)\", \"インターネット動画\", \n",
    "    \"テレビ\", \"録画番組・DVD\", \"ラジオ\", \"新聞\", \"雑誌・マンガ・本\", \n",
    "    \"音楽\", \"休息\", \"その他\", \"不明\"\n",
    "]\n",
    "label_master = pd.read_csv(DIR_GENRE)\n",
    "label_dict = {}\n",
    "for k,v in zip(label_master[\"小分類\"],label_master[\"モデル用定義\"]):\n",
    "    label_dict[k]=v\n",
    "\n",
    "# 行動種別の並び順管理\n",
    "ACTIVITY_ORDERING = ['睡眠', '食事', '身のまわりの用事', '療養・静養', '仕事', '仕事のつきあい', '授業・学内の活動',\n",
    "       '学校外の学習', '炊事・掃除・洗濯', '買い物', '子どもの世話', '家庭雑事', '通勤', '通学', '社会参加',\n",
    "       '会話・交際', 'スポーツ', '行楽・散策', '趣味・娯楽・教養', 'マスメディア接触', '休息']\n",
    "# label_master[\"モデル用定義\"].unique()\n",
    "\n",
    "# 時間帯ごとの行為者率テーブルの処理\n",
    "data_hourly = pd.read_csv(DIR_HOURLY)\n",
    "data_hourly = data_hourly.set_axis([\"Day\",\"Group\",\"Activity\",\"Time\",\"Rate\"],axis=1)\n",
    "data_hourly[\"Time\"] = pd.to_datetime(data_hourly[\"Time\"], format=\"%H:%M\")\n",
    "data_hourly = data_hourly.query(\"Group == @label & Activity in @small & Day == @day\")\n",
    "data_hourly[\"Activity\"] = data_hourly[\"Activity\"].map(label_dict) # 独自定義のラベル適用\n",
    "data_hourly_cleaned = data_hourly[[\"Activity\",\"Time\",\"Rate\"]].groupby([\"Time\",\"Activity\"],as_index=False).sum().copy()\n",
    "data_hourly_cleaned = data_hourly_cleaned.sort_values(by=\"Time\")\n",
    "# 一日の行為者率のテーブルの処理\n",
    "data_full_day = pd.read_csv(DIR_FULL_DAY)\n",
    "df1 = data_full_day.copy()\n",
    "data_full_day = data_full_day.set_axis([\"Day\",\"Group\",\"Activity\",\"DailyRate\",\"NetAverageTime\",\"GrossAverageTime\",\"Gross_SD\"],axis=1)\n",
    "df2 = data_full_day.copy()\n",
    "data_full_day = data_full_day.query(\"Group == @label & Activity in @small & Day == @day\")\n",
    "df3 = data_full_day.copy()\n",
    "data_full_day[\"Activity\"] = data_full_day[\"Activity\"].map(label_dict) # 独自定義のラベル適用\n",
    "data_full_day_cleaned = data_full_day[[\"Activity\",\"DailyRate\"]].groupby([\"Activity\"],as_index=False).sum().copy()\n",
    "df4 = data_full_day.copy()\n",
    "data_full_day_cleaned = sort_df_by_list(data_full_day_cleaned,\"Activity\",ACTIVITY_ORDERING)\n",
    "Orig_P_i = (data_full_day_cleaned[\"DailyRate\"]/100).to_list()\n",
    "# アクティビティと時間のリストを取得\n",
    "time_list_hourly = data_hourly_cleaned['Time'].unique()\n",
    "\n",
    "beta_manual= np.array([\n",
    "    0.0, # 睡眠\n",
    "    0.284926827192975, # 食事\n",
    "    0.0, # 身のまわりの用事\n",
    "    0.0, # 療養・静養\n",
    "    0.9325715108290574, # 仕事\n",
    "    0.0, # 仕事のつきあい\n",
    "    0.39406666910592764, # 授業・学内の活動\n",
    "    1.0, # 学校外の学習\n",
    "    0.0, # 炊事・掃除・洗濯\n",
    "    0.0, # 買い物\n",
    "    0.32887940629086815, # 子どもの世話\n",
    "    1.0, # 家庭雑事\n",
    "    0.001399221544427495, # 通勤\n",
    "    0.0, # 通学\n",
    "    0.23052458820832816, # 社会参加\n",
    "    0.0, # 会話・交際\n",
    "    0.08201993052856074, # スポーツ\n",
    "    1.0, # 行楽・散策\n",
    "    0.18421563581265177, # 趣味・娯楽・教養\n",
    "    1.0, # マスメディア接触\n",
    "    0.21578497836962346, # 休息\n",
    "])\n",
    "\n",
    "\n",
    "ITERATION = 0\n",
    "label,day = sorted_groups[ITERATION]\n",
    "print(f\"Target Group label:{label} day:{day}\")\n",
    "\n",
    "eval2,eval1 = objective_manual(beta_manual,time_list_hourly,data_hourly_cleaned,ACTIVITY_ORDERING,Orig_P_i)\n",
    "print(f\"eval2: {eval2}\")\n",
    "for k,v in zip(ACTIVITY_ORDERING,eval1):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0, # 睡眠\n",
      "0.284926827192975, # 食事\n",
      "0.0, # 身のまわりの用事\n",
      "0.0, # 療養・静養\n",
      "0.9325715108290574, # 仕事\n",
      "0.0, # 仕事のつきあい\n",
      "0.39406666910592764, # 授業・学内の活動\n",
      "1.0, # 学校外の学習\n",
      "0.0, # 炊事・掃除・洗濯\n",
      "0.0, # 買い物\n",
      "0.32887940629086815, # 子どもの世話\n",
      "1.0, # 家庭雑事\n",
      "0.001399221544427495, # 通勤\n",
      "0.0, # 通学\n",
      "0.23052458820832816, # 社会参加\n",
      "0.0, # 会話・交際\n",
      "0.08201993052856074, # スポーツ\n",
      "1.0, # 行楽・散策\n",
      "0.18421563581265177, # 趣味・娯楽・教養\n",
      "0.0, # マスメディア接触\n",
      "0.21578497836962346, # 休息\n"
     ]
    }
   ],
   "source": [
    "for k,v in zip(list(pd.read_pickle(f\"Z:/lab/lifebehavior/βパラメータ_{label}_{day}-1.7931982520658014-.pickle\")),ACTIVITY_ORDERING):\n",
    "    print(f\"{k}, # {v}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T08:42:53.247781600Z",
     "start_time": "2024-09-21T08:42:53.199830200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # pickleで保存\n",
    "# with open(f\"Z:/lab/lifebehavior/βパラメータ_{label}_{day}-{str(best_evaluation)}-.pickle\", 'wb') as f:\n",
    "#     pickle.dump(best_solution, f)\n",
    "# transition_rates = calc_transition_rates(best_solution, time_list_hourly, data_hourly_cleaned, ACTIVITY_ORDERING)\n",
    "# with open(f\"Z:/lab/lifebehavior/遷移確率_{label}_{day}-{str(best_evaluation)}-.pickle\", 'wb') as f:\n",
    "#     pickle.dump(transition_rates, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
